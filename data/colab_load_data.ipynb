{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# optional, nice format for tables on Colab\n",
        "%load_ext google.colab.data_table"
      ],
      "metadata": {
        "id": "AO6iVakMMtFQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up service account for authentication.\n",
        "# IMPORTANT\n",
        "# Make sure you have uploaded file service-account-key.json to Colab before running this cell\n",
        "from google.oauth2 import service_account\n",
        "credentials = service_account.Credentials.from_service_account_file(filename=\"/content/service-account-key.json\", scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
        "# Furthermore, set up connection to BigQuery\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=\"run0002\", credentials=credentials)"
      ],
      "metadata": {
        "id": "2MI9kqaVPxWq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read \"trainings\" dataset (metadata, ~3MB) from BigQuery\n",
        "sql_trainings = \"SELECT * FROM `run0002.student_handout.trainings`\"\n",
        "query_job = client.query(sql_trainings)  # Make an API request.\n",
        "df_trainings = query_job.result().to_dataframe() # Wait for the job to complete.\n",
        "\n",
        "# some sanity checks\n",
        "print(f\"Loaded {len(df_trainings.index)} rows. Here's a preview:\")\n",
        "df_trainings.head()"
      ],
      "metadata": {
        "id": "DxliUw54Qy_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read \"run_logs\" dataset (run logs, ~5GB) from BigQuery\n",
        "# IMPORTANT: This is slow; try to run this cell as little as possible.\n",
        "\n",
        "sql_logs = \"SELECT * FROM `run0002.student_handout.run_logs`\"\n",
        "query_job = client.query(sql_logs)  # Make an API request.\n",
        "df_run_logs = query_job.result().to_dataframe() # Wait for the job to complete.\n",
        "\n",
        "# some sanity checks\n",
        "print(f\"Loaded {len(df_run_logs.index)} rows. Here's a preview:\")\n",
        "df_run_logs.head()"
      ],
      "metadata": {
        "id": "LdLgNkFk7PnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read \"exam_dataset\" dataset (for you to fill in) from BigQuery\n",
        "# You will have to submit this, filled with your predictions, as a .csv file for evaluation\n",
        "# Consider pandas' df_exam.to_csv(\"teamname_submission.csv\", index=False)\n",
        "\n",
        "sql_exam = \"SELECT * FROM `run0002.student_handout.exam_dataset`\"\n",
        "query_job = client.query(sql_exam)  # Make an API request.\n",
        "df_exam = query_job.result().to_dataframe() # Wait for the job to complete.\n",
        "\n",
        "# some sanity checks\n",
        "print(f\"Loaded {len(df_exam.index)} rows. Here's a preview:\")\n",
        "df_exam.head()"
      ],
      "metadata": {
        "id": "mMsihcBBBa2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By now, \n",
        "#Â df_trainings contains all the metadadata for training sessions\n",
        "# df_run_logs contains all the logs for training sessions\n",
        "# df_exam contains the 250 training_ids whose type you will have to predict\n",
        "# \n",
        "# The rest is up to you. Good luck!"
      ],
      "metadata": {
        "id": "muFt3qik71Z1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}